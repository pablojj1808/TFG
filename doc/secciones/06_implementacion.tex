\chapter{Desarrollo de la solución}
A la hora de empezar con la implementación de la solución, debemos comenzar teniendo en
cuenta la arquitectura software que satisface requisitos del sistema de acuerdo con los
usuarios. Es decir, con las historias de usuario que han expresado.

\section{Arquitectura software de la solución}
En esta sección buscamos la mejor forma de que nuestro código quede lo más limpio posible
de forma que nos permita desplegar la aplicación en un entorno cloud, llevar a cabo tests
y poder introducir cambios con facilidad para que el código sea mantenible en el tiempo.

Para ello se ha utilizado el diseño dirigido por el dominio, DDD \textit{Domain Driven
Design}. Este tipo de arquitectura introducida por Eric Evans \cite{ddd_book}
"Domain-Driven-Design - Tackling Complexity in the Hearth of Software, 2004" nos permite
desacoplar el código entre capas, lo que nos permite poder testear escrupulosamente cada
capa de forma independiento ya que no necesita de todo el contexto para su funcionamiento.
La arquitectura dirigida por el dominio nos permite fácilmente aislar la lógica de negocio
en un único sitio y siempre lo más cerca del dominio posible lo que nos permite cumplir
los principios \Gls{SOLID} fácilmente y conseguir un código abierto a su extensión pero
cerrado a su modificación.  


Un requisito fundamental expresado por los usuarios diana a utilizar este proyecto es
poder desplegar fácilmente este proyecto en la nube, gracias a que se ha desarrollado
utilizando capas desacopladas entre si, podríamos distribuir estas capas en distintos
clústeres \footnote{Nos referimos a la técnica por la cual podemos combinar un sistema
para que trabaje paralelamente en un entorno cloud. Lo que conseguimos con esta operación
es una mayor disponibilidad, más velocidad de despacho y escalabilidad del sistema. Como
todo, a cambio tendremos un sistema más costoso de mantener económicamente y un mayor
tiempo de implementación. } sin realizar prácticamente cambios en la implementación.  Es
fundamental desacoplar al máximo todos los componentes y que cada uno tengo una única
responsabilidad cuando se realiza un proyecto en la nube. La principal reto que nos
encontrarremos en este tipo de arquitecturas es la comunicación entre los distintos
componentes.  Sin embargo, una solución a este problema podría ser la comunicación por
eventos, potente pero compleja a nivel técnico y costosa económicamente. Otra solución es
mediante inyección de dependencias, que es la que he empleado en este proyecto, podemos
decir que la debilidad de esta solución reside en que una de las capas puede crecer en
sobremedida y convertirse en un cuello de botella.

\FloatBarrier
\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/costeEvolucion.png}
    \caption{Coste de los cambios en un proyecto dependienso del diseño.
    \footnote{\textit{Active Record} es un patrón de diseño empleado por muchos frameworks
    que unen al modelo las responsabilidades de obtención y creación propias de los
    repositorios.} \href{https://www.cosmicpython.com/book/images/apwp_0205.png}{Fuente}}
    \label{fig:coste-repo-pattern}
\end{figure}
\FloatBarrier


\subsection{Diseño dirigido por el dominio}
En esta sección voy a detallar y justificar el tipo de arquitectura diseñado, su
comportamiento y responsabilidades. En DDD\footnote{Diseño guiado por el dominio, en
inglés: Domain-driven design}, podemos diferenciar tres elementos importantes.

\subsubsection{Entidad}
Las entidades son aquellas clases que representan una entidad del dominio. Estas clases
deben tener una estructura de datos que represente la información de la entidad y unas
responsabilidades concretas. Se caracterizan porque tienen que ser consideradas iguales a
otros objetos aún cuando cuando sus atributos difieren. En las entidades se encuentran las
restricciones del dominio, en ellas se realizan las validaciones de valor e integridad.
Cualquier error o situación inválida hay que notificársela al sistema mediante una
excepción. 

Definir y diseñar los estados inválidos de las entidades y de la aplicación en general es
un apartado fundamental que debemos de realizar con el mismo cuidado que con el que
diseñamos las entidades.

Este proyecto consta de dos entidades: \codeword{Disease} que representa a una enfermedad
y \codeword{Decease} que es sin lugar a duda el modelo más rico en información. Estas
entidades poseen las restricciones de valor como puede ser el tipado de sus atributos o la
satisfacibilidad solo de los valores que tienen sentido semántico. También restricciones
de integridad como por ejemplo, que un objeto de tipo \codeword{Disease} puede tener el
campo \codeword{cie}, nulo.

\subsubsection{Value objects}
Representan los conceptos que no tienen una entidad. Describen características por lo que
solo nos interesan sus atributos. Los value object representan elementos del modelo que se
describen por el \textbf{qué} son, y no por \textbf{quién} o \textbf{cuál} son. Estos
elementos completan y/o forman parte de las entidades del sistema.

En este proyecto la representación en código de las comunidades autónomas corresponde con
un tipo de value object utilizado por la entidad \codeword{Raziel}

\subsubsection{Servicios}
No tienen significado propio suponen la capa que representa las operaciones que no
pertenecen conceptualmente a ningún objeto del dominio concreto. 

En este proyecto, los servicios son el punto de entrada de las peticiones que le hace el
usuario al sistema. Son también los encargados de arrancar todo el proceso de obtención de
los datos.

\subsubsection{Repositorios}
Representan al conjunto de modelos y entidades. Se utilizan para almacenar u ofrecer los
conjuntos de objetos. Suelen suponer una capa de abstracción sobre el sistema de
almacenaje, ya sea una base de datos, unos ficheros en disco o incluso la invocación de
otros servicios externos como puede ser una API. Esta parte es fundamental para poder
modular y preparar las aplicaciones para cambiar de infraestructura sin tener que
modificar el código de programación.

\FloatBarrier
\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/repopattern.png}
    \caption{Colaboración de los repositorios.
    \href{https://www.cosmicpython.com/book/images/apwp_0205.png}{Fuente}}
    \label{fig:repo-pattern}
\end{figure}
\FloatBarrier

En este proyecto hemos implementado este concepto haciendo uso de un
\codeword{AbstractRepository} representado por una clase abstracta. Debido a que,
semánticamente no tiene sentido poder utilizar este tipo de repositorio en sí mismo. Sin
embargo, es usado de clase padre para el resto de repositorios porque impone a las clases
que lo heredan una interfaz uniforme de métodos y abstrae lógicas comunes a este tipo de
concepto.

El proyecto está compuesto por cinco repositorios que obtiene en forma sus modelos
correspondientes. Al existir este tipo de jerarquía y compartir todos estos el mismo tipo
de operación, resulta idónea la aplicación del patrón de diseño de creación
\textit{Factory Method}. Si bien es cierto, que es en lenguajes tipados donde este tipo de
soluciones suponen un cambio radical en cuanto a la comodidad y encaje en la creación de
instancias a lo largo del programa. A nosotros también nos mejora la calidad del código,
pudiendo hacer uso de cualquier repositorio con una sola importación, ya que en otro caso
habría que construir el repositorio \textit{in situ} e inyectarle todas las dependencias
que necesitara.


\subsection{Diagrama arquitectónico de la solución}
A continuación se puede ver un somero diagrama donde podemos observar la conexión entre
los distintos componentes del sistema y la conexión con librerías y frameworks externos. 

\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/arquitectonico.png}
	\caption{ Modelo organizativo del código con sus dependencias externas. }
    \label{fig:worst_f_value}
\end{figure}



\section{Implementación}
En esta sección se van a considerar las decisiones técnicas tomadas en base a los
requisitos y ajuste a la metodología de trabajo expuesta, contemplando siempre como
satisfacen las distintas opciones a alcanzar los objetivos de nuestros usuarios.

\subsection{Configuración}
A la hora de crear un proyecto software, el primer paso que tenemos que hacer es llevar a
cabo una configuración que nos permita arrancar la aplicación de la forma deseada. Este
software está pensado para ejecutarse en la nube, por ello he tenido en cuenta que desde
el principio que tiene que haber una forma de recuperar esta configuración. Además, tengo
que poder establecer distintos parámetros de ejecución según el entorno donde se vaya a
ejecutar. Por tanto, la configuración la almaceno en una clase que se nutre del fichero de
\textit{environment} una única vez ya que queda almacenada en caché. 

\subsection{Lenguaje de programación}
La elección del lenguaje de programación debe de realizarse en base a las necesidades que
tengamos de forma que nos permita satisfacerlas de la mejor forma posible. Quiero un
lenguaje que me permite modelar bien el dominio y me proporcione una buena experiencia de
desarrollo. En este contexto, quiero utilizar un lenguaje que sea orientado a objetos pero
que sea moderno y poco verboso que me permita comenzar a desarrollar con cierta agilidad.

Bajo estas premisas contemplé la posibilidad de emplear JavaScript bajo NodeJS o Python. A
la hora de realizar un proyecto software siempre es necesario utilizar bibliotecas y
código implementado por otras personas para poder llegar más lejos. Este es el principal
motivo que me ha hecho decantarme por \textbf{Python} ya que dispone de una gran comunidad
y de muchas bibliotecas sobre gestión de datos debido a que es muy utilizado en
programación científica.

Otras características a comentar sobre el lenguaje son:
\begin{itemize}
    \item Es un lenguaje que se encuentra en las primeras posiciones como lenguaje más
    utilizado a día de hoy según el índice
    TIOBE\footnote{https://www.tiobe.com/tiobe-index/}. Además, me encuentro muy cómodo
    programando en él.
    \item Es un lenguaje que cuenta con muchísimas bibliotecas, muchas de estas especiales
    para trabajar con datos y ficheros (como \textbf{Pandas}). Abundan también los
    \textit{frameworks} que nos ayudan a construir APIs con él y la mayoría de PaaS
    \footnote{Platform as a Service} soportan este lenguaje.
    \item Es un lenguaje interpretado, débilmente tipado y con una capacidad introspectiva
    muy alta que nos permite metaprogramar.
\end{itemize}

En cuanto a la gestión de dependencias, en el entorno JavaScript tenemos \textit{npm} o
\textit{yarn} que nos permite instalar dependencias de forma sencilla. Para la JVM el
tradicional \textit{maven} es una buena opción o la mas moderna y potente \textit{Gradle}.
En Python se ha extendido el uso de \textbf{Poetry} que de forma muy parecida a
\textit{npm} genera un fichero de configuración \textit{pyproject.toml} donde definimos
las dependencias, las versiones y los paquetes de nuestro proyecto. De el se genra el
fichero \textit{poetry.lock} donde se especifican las versiones instaladas exactas de las
bibliotecas, es necesario utilizar este fichero para realizar despliegues idempotentes.
\footnote{Poder realizar despliegues con exactamente las mismas versiones y orden que se
tienen en dev o en cualquier otro entorno de desarrollo.} así como algunas tareas

En el fichero de configuración \textit{pyproject.toml} nos permite también gestionar las
tareas y podemos especificar órdenes específicas para correr los tests o el lint
fácilmente. Esto facilita enormemente la creación de entornos virtuales de prueba y de
desarrollo tanto el local como por la CI \footnote{Integración continua.}.


\subsubsection{BiBliotecas destacadas}
Como se ha descrito en anteriores, los datos que manejamos están en ficheros CSV. Para
poder trabajar con ellos es necesario utilizar una biblioteca que nos permite trabajar con
estos ficheros. Es necesario poder manejar los datos de estos ficheros con cierta
agilidad. El mayor fichero tiene 967360 líneas y ocupa unos 55 MB aunque no son cifras
cercanas a lo que se considera \textit{big data} necesitamos de una herramienta que nos
permita filtrar, ordenar y hacer cálculos eficientemente sobre estos conjuntos de datos.
La elección de \textbf{Pandas} como biblioteca para trabajar con estos datos es debido a
que es ampliamente utilizada en el mundo Python y encaja en los datos que tenemos. Para la
generación de gráficos se ha utilizado \textbf{Matplotlib}  por su compatibilidad con
\textit{Pandas} que permite realizar gráficas a partir de objetos Dataframe propios de la
biblioteca.

Es necesario poder obtener predicciones basadas en series temporales. Busco que la
predicción sea rápida y automática de forma que no haya que configurar muchos parámetros y
que el pronóstico que ofrece sea ajustable; esto es, que permita modificar y ajustar los
pronósticos agregando conocimiento del dominio.

La primera opción y más famosa en el lenguaje Python es scikit-learn, una biblioteca open
source de machine learning que ofrece infinidad de algoritmos: de clasificación,
regresión, clustering, selección de modelos, preprocesado\ldots

Por otro lado, tenemos \textbf{Prophet} una biblioteca open source para Python y R
desarrollada por Meta\footnote{Anteriormente, Facebook.}. Sus posibilidades son mas
limitadas que las que nos ofrece scikit-learn pero por el contrario es muy básica y
sencilla tanto de instalar como de usar. Además, su funcionalidad es justo la que
buscamos, poder realizar predicciones sobre series temporales. En Prophet, los modelos se
ajustan usando Stan, otra biblioteca de inferencia estadística bayesiana con estimación de
verosimilitud penalizada para Python.

\subsubsection{Interfaz REST}
En aras de que el usuario pueda utilizar estos servicios de forma agnóstica sin tener que
descargarse el código fuente e incluirlo en su proyecto a modo de biblioteca. Algo que por
otra parte, supondría una gran restricción ya que el lenguaje de programación tendría que
ser Python.

Se ha implementado una interfaz de comunicación REST. Como bien es sabido, los servicios
restful se apoyan del estándar HTTP y por tanto, hereda sus conocidas características.
REST es \textit{stateless} cada vez que utilizamos un recurso necesitamos ofrecerle toda
la información identificativa pues carece de memoria, utiliza el formato JSON para el
intercambio de datos y expone una serie de recursos o \textit{endpoints} que son las
operaciones disponibles a realizar utilizando verbos HTTP.

En el universo Python existen dos grandes frameworks para construir servicios restful:
Flask y FastAPI. Flask es un microframework, que dispone de multitud de complementos lo
que te permite construir cualquier servicio configurando correctamente todos estos
complementos. 

FastAPI es un proyecto de código libre mas moderno, de alto rendimiento, según la
 \href{https://fastapi.tiangolo.com}{documentación oficial}, tanto que se podría igualar
 al rendimiento que ofrece NodeJS o Go. Además, nos permite por defecto programar de forma
 asíncrona (muy interesante cuando hay acceso a bases de datos o recursos externos) y nos
 genera de forma automática una documentación OpenAPI.

La API de este software expone dos blueprints \footnote{Llamamos blueprint al conjunto de
recursos que comparte el mismo prefijo de URI (Identificador de recursos uniforme)}

\begin{itemize}
    \item \textit{/data} Definido por el conjunto de recursos disponibles. Todos ellos
    aceptan los siguientes parámetros en la cabecera de las peticiones \codeword{sort}
    para ordenar los datos en base a algún campo, \codeword{limit} para limitar la
    cantidad de datos (por defecto se entregan limitados a 100 elementos), \codeword{page}
    para especificar la página. Y la siguiente estructura JSON como cuerpo de la petición:
    \begin{lstlisting}[caption=Body de una posible petición a \codeword{POST /data/diceases}] 
        { "ID": { "==": [1, 2, 3] }, "CIE": { "!=": "" } }
    \end{lstlisting}
    En este caso estaríamos indicando que queremos los elementos cuyos IDs se encuentran
    en el rango [1, 3] y cuyo campo CIE no es nulo. Los operadores válido son:
    \codeword{==}, \codeword{<}, \codeword{>}

    \item \textit{/managers} Dispone de tres recursos. Uno para generar gráficos lineales
    \ref{fig:graficos-api}: requiere dos variables como parámetros en la cabecera, una
    para indicar la agrupación y otra para la suma, como cuerpo de la llamada podemos
    pasar una query con la estructura especificada anteriormente. Por último, tenemos dos
    recursos para obtener la predicción y la gráfica ajustada en el tiempo que indiquemos.
\end{itemize}

\FloatBarrier
\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/api-managers.png}
	\caption{ Llamada a \codeword{POST /managers/chart} desde
	\href{https://www.postman.com/}{Postman}. Resultado es la gráfica sobre la evolución
	de fallecimientos en toda España a causa del VIH. }
    \label{fig:graficos-api}
\end{figure}
\FloatBarrier

El API es la interfaz por la que el usuario se comunica. Por tanto, al igual que a nivel
de código gestionamos los errores haciendo uso de excepciones, es importante ofrecer al
usuario estos mensajes para que en todo momento sepa que está ocurriendo y si el error es
motivado por su uso, puedo modificarlo. El formato de error es el siguiente cuando estamos
ante una situación inesperada:
\begin{verbatim}
{
    "error_message": "Incorrect query, column ALGO does not exist",
    "code": 422
}
\end{verbatim}
Y cuando se trata de un error de sintaxis con el protocolo. E.g: El JSON introducido como
cuerpo de la petición es incorrecto, obtenemos:
\begin{lstlisting}[caption=Error de sintaxis en el body.] 
    { "detail": [{ "loc": [ "body", 1 ], "msg": "Expecting property name enclosed in
        double quotes: line 1 column 2(char 1)", "type": "value_error.jsondecode", "ctx":
        { "msg": "Expecting property name enclosed in double quotes", "doc": "{", "pos":
        1, "lineno": 1, "colno": 2 } }] }
\end{lstlisting}

En un servicio restful hacemos uso de unos códigos de error que nos ofrece el protocolo
HTTP, estos códigos se clasifican como sigue a continuación:
\begin{itemize}
    \item Respuestas informativas (100–199).
    \item Respuestas satisfactorias (200–299).
    \item Redirecciones (300–399).
    \item Errores de los clientes (400–499).
    \item Errores de los servidores (500–599).
\end{itemize}

En este API se hacen uso de las categorías 1, 3 y 4. Posibles respuestas de este interfaz:
\begin{itemize}
    \item \codeword{200} Ejecución satisfactoria en los endpoints de solicitud de datos.
    \item \codeword{201} Ejecución satisfactoria en los endpoints que generan una imagen
    (gráfico).
    \item \codeword{400} Error del cliente introduciendo un tipo de dato erróneo,
    estructura JSON incorrecta\ldots
    \item \codeword{422} Error del cliente al introducir una query mal formulada, con
    campos incomprensibles o proyecciones sobre campos que no existen en los modelos...
    \item \codeword{500} Error del servidor que los usuarios van a ver por ejemplo cuando
    la fuente de datos esté corrupta y el software no sea capaz de obtenerlos.
\end{itemize}

\subsubsection{Documentación del servicio REST}
Con la ayuda de los recursos que pone a nuestra disposición FastAPI, se ha implementado
una especificación OpenAPI. Esta especificación define una serie de propiedades en un
formato legible por una máquina (suele usarse el formato JSON o YAML).

Gracias a eso podemos generar una documentación basada en HTML que nos permite conocer los
recursos expuestos de la API, los argumentos y las estructuras de las respuestas
esperadas. Además, podemos utilizar esta misma interfaz para probar los
\codeword{endpoints} y realizar llamadas. Los modelos están documentados en el código para
los usuarios que decidan utilizar el software como biblioteca puedan ver dicha
documentación en el IDE que utilicen. Para aquellos que utilicen la API, se ha añadido a
la especificación OpenAPI

\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/openapi.png}
	\caption{ Documentación OpenAPI de la API. }
    \label{fig:worst_f_value}
\end{figure}

\subsubsection{Interfaz de consultas}
Al utilizar una servicio restful para exponer nuestros datos, los recursos retornan toda
la información que conoce sobre el recurso aunque muchas veces solo estemos interesados en
un campo específico, algo que no termina de ser lo que los usuarios han expresado en la
\hyperref[sec:hu2]{historia de usuario 2}. Asimismo, cuando queremos consultar dos
recursos distintos necesitamos realizar dos llamadas distintas. Lo que hace que los
usuarios no tengan libertad absoluta sobre las consultas que realizan a los datos.

Estas restricciones llevan a Meta a liberar publicamente su proyecto iniciado en 2012,
\textbf{GraphQL} que modifica la forma con la que interaccionamos con servidores restful,
éste requiere que se definan unos esquemas indicanto el tipo de los datos por los que
están compuestos los modelos ya que este mecanismo es el que permite que a la hora de
realizar consultas, GraphQL valide los tipos y rechace las consultas que violan esta
aserción.

Comparando GraphLQ desde el punto de vista del modelo CRUD que es el ampliamente usado por
REST, podemos diferenciar tres tipos de operaciones:
\begin{enumerate}
    \item \textbf{Consultas}: equivalen a la operación de lectura. Este tipo de operación
    es bastante más potente porque podemos obtener datos de varios recursos en la misma
    consulta lo que hace mucho más rápido y simple la obtención de datos. Además, no es
    necesario implementar objetos de transferencia con los atributos necesitados ya que
    podemos especificar los atributos que nos interesan en cada una de las consultas.
    \item \textbf{Mutaciones}: equivalen a las operaciones crear, leer, actualizar y
    eliminar. Podemos invocar desde la interfaz GraphQL a una función con sus parámetros
    pertinentes y obtener un resultado en base a lo que haga esa mutación.
    \item \textbf{Suscripciones}: permiten a los clientes obtener en tiempo real cualquier
    modificación que se produzca de los datos. Para conseguirlo es necesario que el
    servidor configure websockets o la interfaz ASGI. \footnote{Asynchronous Server
    Gateway Interface}
\end{enumerate}

GraphQL es un protocolo agnóstico del lenguaje de programaciíon, del sistema de
persistencia que se decida usr y no depende de HTTP. Como podemos observar supone un
cambio importante con respecto a REST donde cada uno de los recursos queda identificado
por una URI que hay que invocar utilizando los verbos HTTP pertinentes. En GraphQL tenemos
un sistema fuertemente tipado y una API que dispone de un único endpoint, todas las
consultas, mutaciones y demás se realizan a traves de un único endpoint.

\subsubsection{Documentación de GraphQL}
Esta tecnología expone un explorador, editor online llamado \textit{GraphiQL} que puede
ser encontrado bajo la ruta \codeword{/graphql} en nuestro servidor. En el se pueden
apreciar las queries disponibles a hacer donde podemos ir desplegando interactivamente y
seleccionando los atributos de los modelos a obtener.

\FloatBarrier
\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/queris-graph.png}
	\caption{ Ejemplo de query en el explorador GraphiQL. }
    \label{fig:graficos-GraphiQL}
\end{figure}
\FloatBarrier

También se pueden observar las mutaciones disponibles con sus campos, podemos filtrar y
buscar campos por coincidencias.

\FloatBarrier
\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/mutaciones-graph.png}
	\caption{ Ejemplo de mutación desde el explorador GraphiQL. }
    \label{fig:graficos-GraphiQL}
\end{figure}
\FloatBarrier

\begin{lstlisting}[caption=Mutación que obtiene nombre de la enfermedad, comiunidad autónoma y número de registros con límite 10 entradas en página 1 .] 
    mutation MyMutation {
        __typename
        getDeceases(query: {defu: {gt: 1}, ccaa: {neq: 99}, ano: {eq: 2008}}, limit: 10) {
            length
            items {
                defu
                causa {
                    name
                }
                ccaa {
                    name
                }
            }
        }
    }
\end{lstlisting}

\section{Conjunto de tests}
Como se ha explicado en la sección sobre \hyperref[sec:ci]{integración continua}, la
batería de tests junto con otras comprobaciones se ejecutan en ese momento.

\begin{lstlisting}[caption=Definición de las etapas de la CI del código del proyecto donde se puede apreciar que se especifican las versiones del lenguaje a comprobar. ]
    name: Python CI on: [push] jobs: build: runs-on: ubuntu-latest strategy: matrix:
python-version: ["3.8","3.9"] steps: - uses: actions/checkout@v2 - uses:
actions/setup-python@v2 with: python-version: "${{ matrix.python-version }}" - name:
Install poetry run: pip install poetry - name: Install poetry dependencies
working-directory: ./code run: poetry install - name: Run lint working-directory: ./code
run: poetry run task lint - name: Run tests working-directory: ./code run: poetry run task
test
\end{lstlisting}

En el código anterior podemos ver como definimos en un fichero de formato YAML que es un
formato de serialización de datos, las distintas etapas y órdenes que tiene que superar el
código.

Nótese, como se indica el S.O. sobre el que se ejecuta, las versiones de Python
compatibles ya que todas estas comprobaciones se realizan para todas las versiones de
Python en las que garantizamos que el software funciona. Y finalmente, las distintas
etapas: instalación de dependencias, lint y tests.

\FloatBarrier
\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/unit-test.png}
    \caption{ Tests unitarios.
    \href{https://martinfowler.com/bliki/images/unitTest/sketch.png}{Fuente}}
    \label{fig:unit-tests}
\end{figure}
\FloatBarrier

Los \textbf{tests unitarios} se encargan de comprobar de unidades individuales del código,
para ello necesitamos una serie de funciones que nos permitan realizar aserciones sobre
los resultados esperados. Además, cuando testeamos los repositorios no queremos cargar los
datos originales que usamos en producción sino unos más livianos y controlados para ello
se ha hecho uso de la herramienta \codeword{pytest} que nos proporciona una librería de
aserciones y \textit{fixtures} para manejar estos recursos.

Para realizar los \textbf{tests de integración} que son competentes de probar el conjunto
y colaboración de las distintas piezas unitarias se ha necesitado arrancar el servidor en
modo de test, FastAPI se encarga de todo este mecanismo, para probar los endpoints
expuestos. Para testear los repositorios se utiliza una fuente de datos falsa que imita la
original pero que es restringida y conocida para que podamos hacer aserciones sobre ella.
Aprovechando el sistema de configuración implementado en el proyecto podemos definir
entornos y en función de ellos proporcionar unas rutas u otras a los repositorios.

Para conocer el nivel de confianza que tenemos se ha calculado el porcentaje de cobertura
que tiene el código. Esto es, la cantidad de lineas que son ejecutadas por los tests para
saber con que confianza podemos realizar cambios que nos garanticen que todo sigue
funcionando. Con más de un 80\% de cobertura es generalmente aceptado que el código está
suficientemente probado ya que algunas veces alcanzar una cobertura mayor tiene más costes
que beneficios.
\footnote{\href{https://www.atlassian.com/continuous-delivery/software-testing/code-coverage}{Code
coverage}}

\FloatBarrier
\begin{figure}[h]
	\centering	
	\includegraphics[width=\textwidth]{doc/logos/imgs/cobertura.jpg}
    \caption{ Informe de cobertura del proyecto.}
    \label{fig:cobertura-tests}
\end{figure}
\FloatBarrier

